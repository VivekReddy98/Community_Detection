{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from py2neo import Graph, Node, Relationship, Database\n",
    "from py2neo.matching import NodeMatcher\n",
    "from py2neo.database import Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = ['amazon']  #'dblp', 'youtube']\n",
    "variant = ['small',] #['medium', 'large'] #Omitted original for now\n",
    "di = {'amazon':'1', 'dblp':'2', 'youtube':'3', 'small':'4', 'medium':'5', 'large':'6'}\n",
    "\n",
    "class ID_generators(object):\n",
    "    def __init__(self, category, variant, dict_identify):\n",
    "        self.cat = category\n",
    "        self.var = variant\n",
    "        self.di = dict_identify\n",
    "        \n",
    "    def label_gen(self):\n",
    "        return self.cat+\"_\"+self.var\n",
    "    \n",
    "    def name_gen(self,i):\n",
    "        return self.cat+\"_\"+self.var+\"_\"+str(i)\n",
    "    \n",
    "    def uniq_id(self, i):\n",
    "        index = str(i)\n",
    "        index = ''.join([\"0\" for i in range(0,6-len(index))]) + index\n",
    "        return int(di[self.cat]+di[self.var]+index)\n",
    "    \n",
    "    def gen_cluster_id(self, i, prev=None):\n",
    "        if prev==None:\n",
    "            return '|' + str(i) + '|'\n",
    "        else:\n",
    "            return prev+str(i)+'|'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.environ['GDMPATH']\n",
    "graph = Graph(\"bolt:localhost:7474/databases/gdm.db\", auth=(\"neo4j\", \"\"))\n",
    "graph.delete_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/amazon/amazon.graph.small\n"
     ]
    }
   ],
   "source": [
    "graph.delete_all()\n",
    "schema = Schema(graph)\n",
    "findNode = NodeMatcher(graph)\n",
    "\n",
    "for cat in category:\n",
    "    for var in variant:\n",
    "        filename = \"datasets/{}/{}.graph.{}\".format(cat, cat, var)\n",
    "        Id = ID_generators(cat,var,di)\n",
    "        tx = graph.begin()\n",
    "        with open(parent_dir+filename) as fp:\n",
    "            elements = fp.readline().strip().split(\" \")\n",
    "            for i in range(0, int(elements[0])):\n",
    "                tx.create(Node(ID=3000, Id.label_gen(), name=Id.name_gen(i),uid=Id.uniq_id(i),cluster=Id.gen_cluster_id(0)))\n",
    "            tx.commit()\n",
    "        schema.create_index(ID.label_gen(), 'uid')\n",
    "        print(filename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(_2298:amazon_small {cluster: '|0|', name: 'amazon_small_250', uid: 14000250})\n"
     ]
    }
   ],
   "source": [
    "ID = ID_generators('amazon',\"small\",di)\n",
    "print(findNode.match(ID.label_gen(), uid=ID.uniq_id(250)).first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/amazon/amazon.graph.small\n",
      "datasets/amazon/amazon.graph.medium\n",
      "datasets/amazon/amazon.graph.large\n",
      "datasets/dblp/dblp.graph.small\n",
      "datasets/dblp/dblp.graph.medium\n",
      "datasets/dblp/dblp.graph.large\n",
      "datasets/youtube/youtube.graph.small\n",
      "datasets/youtube/youtube.graph.medium\n",
      "datasets/youtube/youtube.graph.large\n"
     ]
    }
   ],
   "source": [
    "for cat in category:\n",
    "    for var in variant:\n",
    "        filename = \"datasets/{}/{}.graph.{}\".format(cat, cat, var)\n",
    "        ID = ID_generators(cat,var,di)\n",
    "        tx = graph.begin()\n",
    "        with open(parent_dir+filename) as fp:\n",
    "            elements = fp.readline().strip().split(\" \")\n",
    "            for j in range(0, int(elements[1])):\n",
    "                nodes = fp.readline().strip().split(\" \")\n",
    "                Node1 = findNode.match(ID.label_gen(), uid=ID.uniq_id(int(nodes[0]))).first()\n",
    "                Node2 = findNode.match(ID.label_gen(), uid=ID.uniq_id(int(nodes[1]))).first()\n",
    "                tx.create(Relationship(Node1, \"KNOWS\", Node2))\n",
    "                tx.create(Relationship(Node2, \"KNOWS\", Node1))\n",
    "            tx.commit()\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23015296061833698\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for cat in category:\n",
    "    for var in variant:\n",
    "        filename = \"datasets/{}/{}.graph.{}\".format(cat, cat, var)\n",
    "        ID = ID_generators(cat,var,di)\n",
    "#         tx = graph.begin()\n",
    "        with open(parent_dir+filename) as fp:\n",
    "            elements = fp.readline().strip().split(\" \")\n",
    "            for j in range(0, int(elements[1])):\n",
    "                nodes = fp.readline().strip().split(\" \")\n",
    "                Node1 = findNode.match(ID.label_gen(), uid=ID.uniq_id(int(nodes[0]))).first()\n",
    "                Node2 = findNode.match(ID.label_gen(), uid=ID.uniq_id(int(nodes[1]))).first()\n",
    "end = time.time()\n",
    "print((end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(_2048:amazon_small {cluster: '|0|', name: 'amazon_small_0', uid: 14000000})\n"
     ]
    }
   ],
   "source": [
    "print(findNode.get(2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1142535 = hash(Node(ID.label_gen(), name=ID.name_gen(i),uid=ID.uniq_id(i),cluster=ID.gen_cluster_id(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findNode = NodeMatcher(graph)\n",
    "findNode.get(139876064017928)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = ID_generators('amazon','large',di)\n",
    "tx = graph.begin()\n",
    "tx.create(Node(ID=5000, label=Id.label_gen(), name=Id.name_gen(i),uid=Id.uniq_id(i),cluster=Id.gen_cluster_id(0)))\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx = graph.begin()\n",
    "tx.run('CREATE INDEX ON :{}(uid)'.format('amazon_small'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDM_P2",
   "language": "python",
   "name": "gdm_p2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
